{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_virus_entities(headline_doc):\n",
    "    for ent in headline_doc.ents:\n",
    "        if ent.label_ in ['PERSON', 'NORP', 'FAC', 'ORG', 'EVENT', 'WORK_OF_ART', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL']:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "assert not has_virus_entities(nlp('by train'))\n",
    "assert has_virus_entities(nlp('Bill Gates'))\n",
    "assert has_virus_entities(nlp('European commission'))\n",
    "assert has_virus_entities(nlp('by Google'))\n",
    "assert has_virus_entities(nlp('$1 billion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "def has_positive_synset(token):\n",
    "    def get_swn_tag(token_tag):\n",
    "        swn_tag = ''\n",
    "        if token_tag in ['NN', 'NNP', 'NNPS', 'NNS']:\n",
    "            swn_tag = 'n'\n",
    "        if token_tag in ['VB', 'VBD', 'VBG', 'VBP', 'VBN', 'VBZ']:\n",
    "            swn_tag = 'v'\n",
    "        if token_tag in ['JJ', 'JJR', 'JJS']:\n",
    "            swn_tag = 'a'\n",
    "        if token_tag in ['RB', 'RBR', 'RBS']:\n",
    "            swn_tag = 'r'\n",
    "        return swn_tag\n",
    "\n",
    "    swn_tag = get_swn_tag(token.tag_)\n",
    "    if not swn_tag:\n",
    "        return False\n",
    "\n",
    "    synsets = swn.senti_synsets(token.lemma_, swn_tag)\n",
    "    pos_scores = [synset.pos_score() for synset in synsets]\n",
    "    if pos_scores:\n",
    "        return max(pos_scores) > 0.6\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_positive(headline_str):\n",
    "    for token in headline_str:\n",
    "        if has_positive_synset(token):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "assert is_positive(nlp('I am happy'))\n",
    "assert not is_positive(nlp('nothing happened'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_comparison(headline_doc):\n",
    "    for token in headline_doc:\n",
    "        if token.tag_ in ['JJR', 'JJS', 'RBR', 'RBS']:\n",
    "            return True\n",
    "    return False           \n",
    "\n",
    "assert not has_comparison(nlp('by train'))\n",
    "assert has_comparison(nlp('most beautifull'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_BREAKING_HYPHEN = u'\\u2011'\n",
    "\n",
    "def replace_hyphens(headline_str):\n",
    "    headline_ch_list = list(headline_str)\n",
    "    for m in re.finditer(r'[a-zA-Z]-[a-zA-Z]', headline_str):\n",
    "        headline_ch_list[m.start() + 1] = NON_BREAKING_HYPHEN\n",
    "\n",
    "    return \"\".join(headline_ch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('examiner-headlines.txt') as f:\n",
    "    headlines_strs = f.readlines()\n",
    "\n",
    "headlines_strs = [replace_hyphens(headline_str) for headline_str in headlines_strs]\n",
    "tokenized_headlines = [nlp(headline_str) for headline_str in headlines_strs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_virus_entities = 0\n",
    "positives = 0\n",
    "with_comparisons = 0\n",
    "\n",
    "for headline_doc in tokenized_headlines:\n",
    "    if has_virus_entities(headline_doc):\n",
    "        with_virus_entities += 1\n",
    "    if is_positive(headline_doc):\n",
    "        positives += 1\n",
    "    if has_comparison(headline_doc):\n",
    "        with_comparisons += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With virus entities:  0.6254\n",
      "Positive:  0.265\n",
      "With comparisons:  0.046\n"
     ]
    }
   ],
   "source": [
    "print('With virus entities: ', with_virus_entities / len(tokenized_headlines))\n",
    "print('Positive: ', positives / len(tokenized_headlines))\n",
    "print('With comparisons: ', with_comparisons / len(tokenized_headlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
