# Оригінальне завдання - TASK 08
# Синтаксичний аналіз

## I. Покращення парсера залежностей

Візьміть за основу [парсер залежностей, побудований на практичному занятті](../../../lectures/08-dep-parser-uk.ipynb), і зробіть мінімум одну ітерацію для покращення якості.

Варіанти покращення:
1. підберіть кращі ознаки
2. спробуйте інший класифікатор
3. замініть статичний оракул динамічним
4. додайте класифікацію типів залежностей
5. додайте опрацювання непроективних дерев
6. ваші ідеї

Корисні посилання:
* [UD-корпус для української](https://github.com/UniversalDependencies/UD_Ukrainian-IU/)
* [Зручна бібліотека для роботи з форматом CoNLL](https://github.com/EmilStenstrom/conllu)
* Стаття з блогу Matthew Honnibal - [Parsing English in 500 Lines of Python](https://explosion.ai/blog/parsing-english-in-python)
* Книга про парсери залежностей - [Dependency Parsing by Kübler, McDonald, and Nivre](https://books.google.com.ua/books?id=k3iiup7HB9UC&pg=PA21&hl=uk&source=gbs_toc_r&cad=4#v=onepage&q&f=false)
* Гарний огляд типів парсера залежностей та оракулів - [Improvements in Transition Based Systems for Dependency Parsing](http://paduaresearch.cab.unipd.it/8004/1/Tesi.pdf)

## II. Використання парсера на нових даних

Виберіть кілька випадкових речень українською мовою на побудуйте дерева залежностей для них, використовуючи свій парсер.

Для токенізації можна використати https://github.com/lang-uk/tokenize-uk.

Для частиномовного аналізу можна використати https://github.com/kmike/pymorphy2. Зважте, що частиномовні теги в UD та в pymorphy2 відрізняються, зокрема pymorphy2 не розрізняє типи сполучників. Нижче подано спосіб вирівняти ці дві нотації:

```python
DET = ['інакший', 'його', 'тамтой', 'чий', 'їх', 'інш.', 'деякий', 'ввесь', 'ваш', 
       'ніякий', 'весь', 'інший', 'чийсь', 'жадний', 'другий', 'кожний', 
       'такий', 'оцей', 'скілька', 'цей', 'жодний', 'все', 'кілька', 'увесь', 
       'кожній', 'те', 'сей', 'ін.', 'отакий', 'котрий', 'усякий', 'самий', 
       'наш', 'усілякий', 'будь-який', 'сам', 'свій', 'всілякий', 'всенький', 'її', 
       'всякий', 'отой', 'небагато', 'який', 'їхній', 'той', 'якийсь', 'ин.', 'котрийсь', 
       'твій', 'мій', 'це']

PREP = ["до", "на"]

mapping = {"ADJF": "ADJ", "ADJS": "ADJ", "COMP": "ADJ", "PRTF": "ADJ",
           "PRTS": "ADJ", "GRND": "VERB", "NUMR": "NUM", "ADVB": "ADV",
           "NPRO": "PRON", "PRED": "ADV", "PREP": "ADP", "PRCL": "PART"}

def normalize_pos(word):
    if word.tag.POS == "CONJ":
        if "coord" in word.tag:
            return "CCONJ"
        else:
            return "SCONJ"
    elif "PNCT" in word.tag:
        return "PUNCT"
    elif word.normal_form in PREP:
        return "PREP"
    else:
        return mapping.get(word.tag.POS, word.tag.POS)
```

Запишіть ваші спостереження та результати в окремий файл.

## Оцінювання

Крайній термін: 27.04.2019

Оцінка: 80% за 8-ий тиждень (по 40% за кожне завдання)

# Що робилося
Не написав "рішення", бо не досяг того, чого хотів. Але, опишу, які експерименти 
було зроблено.

## Ціль
Дуже захотілося зробити щось нестандартне, щоб можна було залежності створювати напряму. 

В мене була гіпотеза, що тут можна застосувати якийсь слабкий класифікатор, який 
може оцінити кожний зв'язок окремо, а потім, на базі цього оцінювання (для кожного
із зв'язків) та штрафів за неналежну структуру зв'язків (про це далі), можна
знайти оптимальну структуру зв'язків у всьому реченні.

## 1. Слабкий класифікатор
Спочатку я натренував слабкий класифікатор. Для цього, треба запустити модуль 
[weak_classifier.py](weak_classifier.py). Він бере тренувальний набір дерев, та
для кожного з токенів створює два семпла для наступного тренування:

1. Фічі для правильнго зв'язку з батьком (true-sample).
2. Фічі для рандомного зв'язку, який не співпадає з батьком (false-sample). 

Також був варіант, коли в негативні фічі потрапляли всі інши зв'язки окрім 
правильного, але такий вариант було відкинуто через слабшу роботу на 
наступному кроці.

У якості фіч використано (для обох токенів):
- casefolded токен
- чи токен починається з великої літери
- префікси та суфікси довжиною 1...3
- позиції в речені
- модуль різниці між позиціями токенів в реченні.

Класифікатор (логістична регресія) було навчено на цих фічах та семплах і віп 
показав такий результат (на тестових деревах):

```
python.exe weak_classifier.py
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.1s finished

Total number of features:  111796
              precision    recall  f1-score   support

       False       0.86      0.78      0.82     16037
        True       0.80      0.88      0.84     16037

   micro avg       0.83      0.83      0.83     32074
   macro avg       0.83      0.83      0.83     32074
weighted avg       0.83      0.83      0.83     32074
```

## 2. Пряма відбудова дерева
Маючи слабкий класифікатор, далі я сподівався відновити повну структуру 
дерева за допомогою генетичного алгоритму (далі ГА або GA).

Перш за все, нам треба вибрати кодування геному - для цієї задачі воно
елементарне. Це ціпочка (масив) цілих чисел, які кодують номер+1 батька
для токена, який знаходиться на цієї позиції (код 0 зарезервовано для
кореня, що збігається з кодуванням для дерев).

При такому вигляді геному, можна застосовувати стандартний оператор
двоточечного кросоверу, а в якості мутації - рандомну заміну якогось
зв'язку на випадковий до любого іншого токена, або до кореня.

Іншим важливим елементом, який спрямовує еволюцію, є фітнес-функція.

Щоб знайти пристосованість якогось геному, я спробував зробити таку 
процедуру:

- Сумуємо оцінки кожного зв'язка за допомогою слабкого 
класифікатора, який було треновано на минулому кроці. Через те,
що в ГА теж краще використовувати більш гладкі функції, така
оцінка обчислювалася не за допомогою predict, а наступним чином:
    
```python
f = relation_to_features(tokens, child_pos, head_pos)
prediction = classifier.predict_proba([f])
fit = prediction[0][1] - prediction[0][0]
```

Тобто, використовувалася різниця між правдоподібністю віднесення
зв'язку до позитивного та негативного класів.

- А далі накладалися штрафи за вади у структурі графа:
  - За кожний токен, який не має лінку до рута - штраф 10
  - За кожен зв'язок до рута окрім першого - штраф 10
  - За 0 зв'язків до рута - штраф 10

Окремо за зв'язок з самим собою не штрафував, бо це і так 
автоматично створює цикл, який не іде до рута.

Створивши такі правила, я запустив еволюцію для відтворення
перших 10 тестових дерев. Еволюція першого дерева показана
докладно, для інших детальний режим було відключено. На прогоні
застосовувалася популяція з 1000 особин, максимально було 
дозволено 1000 епох, але є детекція, що еволюція знайшла 
найкращу особину достроково. Ймовірність мутації - 0.3

```
python.exe tree_maker.py
864 sentences loaded.
...
Start evolution
Epoch 0, the best genome: (2.084840842526697)[8, 1, 1, 6, 3, 10, 1, 0, 7, 7]
Epoch 1, the best genome: (2.0899702571667547)[5, 3, 1, 10, 0, 3, 6, 9, 7, 7]
Epoch 2, the best genome: (1.5058001232708642)[2, 3, 0, 1, 6, 1, 3, 6, 5, 4]
Epoch 3, the best genome: (2.1132008046604627)[7, 3, 0, 1, 6, 1, 3, 6, 5, 5]
Epoch 4, the best genome: (2.6610727448775595)[0, 6, 8, 1, 3, 9, 6, 6, 1, 1]
Epoch 5, the best genome: (3.454997029651257)[0, 6, 8, 1, 3, 1, 6, 6, 1, 1]
Epoch 6, the best genome: (3.3638387955756506)[4, 3, 6, 6, 6, 7, 0, 7, 6, 3]
Epoch 7, the best genome: (3.873446243391236)[4, 1, 0, 3, 3, 3, 1, 3, 6, 1]
Epoch 8, the best genome: (2.782539217649847)[6, 3, 9, 1, 3, 3, 1, 1, 0, 9]
Epoch 9, the best genome: (3.0638934074112427)[6, 3, 6, 1, 0, 5, 1, 6, 7, 9]
Epoch 10, the best genome: (3.8723630093946104)[0, 3, 1, 5, 7, 7, 1, 6, 3, 9]
Epoch 11, the best genome: (5.475535782326896)[0, 3, 1, 6, 3, 7, 1, 7, 7, 9]
Epoch 12, the best genome: (4.749021067011229)[6, 1, 1, 1, 6, 7, 0, 7, 6, 1]
Epoch 13, the best genome: (4.455686281346738)[0, 6, 7, 6, 3, 3, 1, 6, 3, 3]
Epoch 14, the best genome: (5.449993951700085)[0, 3, 1, 6, 3, 3, 1, 6, 3, 3]
Epoch 15, the best genome: (5.307126879389077)[0, 1, 1, 1, 7, 3, 1, 6, 3, 9]
Epoch 16, the best genome: (5.4209940287067075)[0, 1, 6, 3, 3, 1, 3, 6, 7, 9]
Epoch 17, the best genome: (4.868844720883555)[0, 6, 1, 3, 7, 7, 1, 6, 3, 9]
Epoch 18, the best genome: (5.75870163072817)[0, 3, 1, 3, 6, 7, 1, 7, 3, 7]
Epoch 19, the best genome: (5.75870163072817)[0, 3, 1, 3, 6, 7, 1, 7, 3, 7]
Epoch 20, the best genome: (5.642318838639172)[0, 3, 1, 3, 6, 7, 1, 7, 6, 9]
Epoch 21, the best genome: (5.043689758845405)[0, 3, 7, 3, 6, 7, 1, 7, 6, 9]
Epoch 22, the best genome: (5.6668900430067985)[0, 3, 1, 1, 1, 7, 1, 6, 3, 7]
Epoch 23, the best genome: (5.3422716547646605)[0, 3, 7, 3, 6, 7, 1, 7, 6, 6]
Epoch 24, the best genome: (5.1781998962532665)[6, 1, 0, 3, 1, 7, 3, 6, 7, 7]
Epoch 25, the best genome: (5.2152150174261)[6, 1, 0, 3, 6, 7, 3, 6, 7, 7]
Epoch 26, the best genome: (5.410911977629313)[0, 1, 7, 3, 6, 7, 1, 7, 6, 6]
Epoch 27, the best genome: (5.7740703038891485)[0, 3, 1, 6, 3, 7, 1, 7, 6, 7]
Epoch 28, the best genome: (5.410911977629313)[0, 1, 7, 3, 6, 7, 1, 7, 6, 6]
Epoch 29, the best genome: (5.342754251436567)[0, 3, 7, 3, 6, 7, 1, 7, 6, 7]
Epoch 30, the best genome: (5.391206258929335)[3, 1, 6, 3, 6, 0, 6, 6, 6, 7]
Epoch 31, the best genome: (5.391736229958244)[3, 1, 6, 3, 6, 0, 6, 6, 7, 7]
Epoch 32, the best genome: (5.392157099165139)[3, 1, 6, 3, 6, 0, 6, 7, 7, 7]
Epoch 33, the best genome: (5.285598189248855)[3, 3, 6, 3, 1, 0, 6, 6, 7, 6]
Epoch 34, the best genome: (5.391206258929335)[3, 1, 6, 3, 6, 0, 6, 6, 6, 7]
Epoch 35, the best genome: (5.4175702489869355)[3, 1, 6, 3, 3, 0, 6, 6, 7, 6]
Epoch 36, the best genome: (5.41805284565884)[3, 1, 6, 3, 3, 0, 6, 6, 7, 7]
Epoch 37, the best genome: (5.417943743836824)[3, 1, 6, 3, 3, 0, 6, 7, 6, 7]
Epoch 38, the best genome: (5.41805284565884)[3, 1, 6, 3, 3, 0, 6, 6, 7, 7]
Epoch 39, the best genome: (5.417991118193829)[3, 1, 6, 3, 3, 0, 6, 7, 7, 6]
Epoch 40, the best genome: (5.418473714865733)[3, 1, 6, 3, 3, 0, 6, 7, 7, 7]
Epoch 41, the best genome: (5.418473714865733)[3, 1, 6, 3, 3, 0, 6, 7, 7, 7]
Epoch 42, the best genome: (5.418473714865733)[3, 1, 6, 3, 3, 0, 6, 7, 7, 7]
Epoch 43, the best genome: (5.418473714865733)[3, 1, 6, 3, 3, 0, 6, 7, 7, 7]
Epoch 44, the best genome: (5.418473714865733)[3, 1, 6, 3, 3, 0, 6, 7, 7, 7]
Epoch 45, the best genome: (5.418473714865733)[3, 1, 6, 3, 3, 0, 6, 7, 7, 7]
Early evolution stop at epoch 46
Restored:  [3, 1, 6, 3, 3, 0, 6, 6, 6, 7]
Tokens: ['Продавши', 'свій', 'шедевр', 'Меценатові', ',', 'еллінський', 'скульптор', 'споневажив', 'саме', 'мистецтво', ':', 'Ти', 'не', 'продався', ',', '–', 'гірше', '!']
True genome: (10.368292410805038)[8, 3, 1, 1, 1, 7, 8, 0, 10, 8, 14, 14, 14, 8, 17, 17, 14, 14]
Restored   : (-118.42798287003362)[0, 1, 1, 1, 1, 8, 8, 9, 7, 14, 14, 14, 14, 8, 14, 14, 14, 14]

Tokens: ['Ти', 'віддався', 'У', 'руки', 'ворогу', ',', 'як', 'мертва', 'глина', ',', 'З', 'якої', 'кожне', 'виліпить', ',', 'що', 'хоче', '.']
True genome: (11.017678228424025)[2, 0, 4, 2, 2, 9, 9, 9, 2, 14, 12, 14, 14, 9, 17, 17, 14, 2]
Restored   : (13.833465527253756)[2, 0, 2, 2, 2, 2, 2, 9, 14, 14, 14, 14, 14, 17, 14, 14, 2, 17]

Tokens: ['Та', 'хто', 'ж', 'тобі', 'натхне', 'вогонь', 'живий', ',', 'Коли', 'з', 'творця', 'ти', 'творивом', 'зробився', '?']
True genome: (3.7476724043286365)[5, 5, 2, 5, 0, 5, 6, 14, 14, 11, 14, 14, 14, 5, 5]
Restored   : (6.117770271514409)[2, 5, 5, 5, 0, 5, 5, 7, 7, 14, 14, 14, 7, 13, 14]

Tokens: ['Зробитися', '«', 'творивом', '»', '–', 'означає', 'ще', 'і', 'втратити', 'владу', 'над', 'матеріалом', ',', 'формою', '.']
True genome: (10.568774810609792)[6, 3, 1, 3, 6, 0, 6, 9, 6, 9, 12, 10, 14, 12, 6]
Restored   : (13.229025773414094)[0, 6, 1, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6]

Tokens: ['У', 'листі', 'до', 'матері', ',', 'написаному', 'якраз', 'у', 'час', 'роботи', 'над', '«', 'Оргією', '»', ',', 'авторка', 'з', 'цього', 'приводу', 'якось', 'потвердила', ',', 'що', 'не', 'буде', '«', 'загрожувати', 'переходом', 'в', 'чужу', 'літературу', ',', 'як', 'то', 'роблять', 'інші', ',', 'бо', 'то', '«', 'себе', 'дороже', 'стоит', '»', '»', '.']
True genome: (19.947002368282895)[2, 21, 4, 2, 6, 2, 9, 9, 6, 9, 13, 13, 10, 13, 6, 21, 19, 19, 21, 21, 0, 27, 27, 25, 27, 27, 21, 27, 31, 31, 28, 35, 35, 35, 27, 35, 41, 41, 41, 41, 27, 41, 41, 41, 27, 21]
Restored   : (34.07883056954818)[4, 4, 2, 10, 4, 2, 4, 4, 4, 21, 4, 4, 4, 13, 21, 21, 13, 21, 21, 21, 0, 21, 21, 21, 21, 21, 21, 30, 30, 21, 35, 35, 30, 35, 21, 35, 35, 35, 35, 42, 35, 35, 42, 42, 42, 42]

Tokens: ['Але', 'натомість', ',', 'втомившись', 'редакційними', 'чварами', 'й', 'непорозуміннями', ',', 'готова', 'зважитися', '«', 'не', 'давати', 'їм', 'ні', 'стрічки', '»', ',', 'мовчати', ',', 'писати', 'для', 'себе', ',', 'аніж', 'терпіти', 'зневагу', '.']
True genome: (11.435408013808585)[10, 10, 4, 10, 6, 4, 8, 6, 4, 0, 10, 14, 14, 11, 14, 17, 14, 14, 20, 14, 22, 14, 24, 22, 27, 27, 10, 27, 10]
Restored   : (17.96794895307512)[4, 4, 4, 15, 4, 4, 4, 4, 11, 11, 8, 11, 14, 11, 0, 17, 11, 17, 20, 17, 22, 20, 22, 22, 22, 27, 22, 27, 27]

Tokens: ['Це', 'власне', 'такі', 'роздуми', 'вплинули', 'на', 'фатальне', 'рішення', 'Антея', '.']
True genome: (6.778603497507959)[5, 3, 4, 5, 0, 8, 8, 5, 8, 5]
Restored   : (7.6482001159827355)[5, 5, 5, 5, 8, 5, 5, 0, 8, 5]

Tokens: ['Блискуче', 'обізнана', 'у', 'європейських', 'літературах', ',', 'знаючи', 'тексти', 'не', 'з', 'других', 'рук', ',', 'Леся', 'Українка', 'легко', 'позбувається', 'тої', 'отрутної', 'пошани', 'до', 'винятковості', '«', 'російського', 'генія', '»', ',', 'якою', 'вигодовували', 'цілі', 'покоління', 'українців', '.']
True genome: (19.433040128030807)[2, 17, 5, 5, 2, 7, 2, 7, 11, 12, 12, 7, 7, 17, 14, 17, 0, 20, 20, 17, 22, 20, 25, 25, 22, 25, 29, 29, 20, 31, 29, 31, 17]
Restored   : (24.61894738715876)[2, 7, 2, 2, 2, 7, 8, 17, 7, 7, 17, 17, 17, 17, 17, 29, 16, 17, 17, 17, 17, 17, 29, 29, 29, 29, 29, 29, 0, 29, 29, 29, 31]

Tokens: ['(', 'Про', 'необхідність', 'подолати', '«', 'культурний', 'епігонізм', '»', ',', 'вплив', '«', 'російського', 'культурника', '»', 'і', 'піти', '«', 'до', 'джерел', '»', 'пристрасно', 'полемізували', 'ще', 'й', 'у', 'дискусії', 'середини', 'двадцятих', 'років', ',', 'це', 'важлива', 'теза', 'статей', 'Хвильового', 'й', 'Зерова', '.', ')']
True genome: (16.173030859747243)[22, 3, 22, 3, 7, 7, 4, 7, 10, 7, 13, 13, 10, 13, 16, 4, 19, 19, 16, 19, 22, 0, 22, 26, 26, 22, 26, 29, 27, 33, 33, 33, 22, 33, 34, 37, 35, 22, 22]
Restored   : (26.886045856331467)[3, 3, 4, 6, 4, 0, 6, 10, 10, 7, 10, 10, 10, 10, 16, 10, 22, 22, 22, 22, 22, 16, 22, 22, 22, 22, 22, 32, 22, 32, 32, 29, 32, 32, 32, 32, 32, 32, 34]
```  

Що ми бачимо:

Майже у всіх випадках (крім одного), ГА знайшов комбінацію, яка 
має краще значення фітнес-функції, ніж правильне дерево. І ці 
дерева майже не співпадають з правильними.

Таким чином, немає сенсу далі щось робити з ГА, та рахувати
показники якості, через те, що гіпотеза
із застосуванням слабого класифікатора виявилася хибною в такій 
імплементації.


## Мої висновки:

- Для того, щоб можна було напряму побудувати дерево, треба або
змінити фітнес-функцію, або накласти якійсь додаткові обмеження
на структуру дерева. Нажаль, я вже не встигаю придумати тут 
чогось принципово іншого. Була думка щодо штрафу за зв'язки, що
перетинаються, але чим тоді цей підхід буде краще за автомат
з оракулом (якщо, звичайно спрацює)?

- Мені дуже сподобалось, що, хоча дерево і не дуже правильне з
точки зору конкретних зв'язків, але має досить правильну структуру
без циклів та одним зв'язком до рута. І все це було знайдено
за допомогою ГА автоматично, лише за допомогою штрафів.

# По курсовому проекту

https://github.com/serge-sotnyk/tesufr

- Додано ще одне ядро для анотації (SumaCore), яке використовує алгоритм TextRank 
як для ключових слів, так і екстракції речень.
- Оптимізовано код.
- Додано setup.py, у себе збирав пакет. Хочу ще потестувати, та викласти для
установки через pip

Показники якості для обох анотуючих ядер:

```
python.exe tesufr/evaluate_with_corpora.py
Check metrics for BBC News / FallbackCore
100%|██████████| 445/445 [00:10<00:00, 43.59it/s]
{'rouge_1': 0.5489569227407518, 'rouge_2': 0.44733345610434844, 'rouge_3': 0.4047945705861156, 'rouge_4': 0.3695602606075601, 'bleu': 41.611864189349895}
Check metrics for BBC News / SummaCore
100%|██████████| 445/445 [00:31<00:00, 14.65it/s]
{'rouge_1': 0.7736740467482042, 'rouge_2': 0.7057150991231917, 'rouge_3': 0.6553423520070746, 'rouge_4': 0.6053681996983519, 'bleu': 68.8648511166897}
Check metrics for Krapivin2009 / FallbackCore
100%|██████████| 461/461 [00:44<00:00, 11.13it/s]
{'precision': 0.4030932949690004, 'recall': 0.14229306838749253, 'f1': 0.20524058808381612, 'rouge_1': 0.024238965325505984, 'rouge_2': 0.008135379808691693, 'rouge_3': 0.003927411070078904, 'rouge_4': 0.0025979649815830105, 'bleu': 0.5387344660957267}
Check metrics for Krapivin2009 / SummaCore
100%|██████████| 461/461 [19:07<00:00,  2.26s/it]
{'precision': 0.202779777328585, 'recall': 0.17495413450880182, 'f1': 0.1809694582787395, 'rouge_1': 0.026164841589721592, 'rouge_2': 0.006921741294599503, 'rouge_3': 0.001973890294264275, 'rouge_4': 0.0007699996243221003, 'bleu': 0.37001081799842556}
```

Корпус Krapivin2009 має набагато довші тексти, то ж менші значення 
якості на ньому - очікувані.