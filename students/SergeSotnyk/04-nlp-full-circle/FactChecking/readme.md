# Завдання
## Перевірка фактів на достовірність
У межах цієї задачі ви побудуєте систему видобування фактів на правилах, а також інструменти для оцінювання якості роботи цієї системи.

1. Домен

    Виберіть домен, для якого можна побудувати невелику базу даних на основі DBPedia. Приклади доменів:

    * актор і фільми, в яких він знімався;
    * письменник і книжки, які він написав;
    * музичний гурт і його учасники/концерти/альбоми з роками діяльності/випуску;
    * компанія і всі її CEO/CTO з роками діяльності;
    * людина і всі її місця роботи з часовими проміжками;
    * політик і політичні партії, в яких він брав участь, з роками діяльності;
    * винахідник та його винаходи;
    * спортсмени і їх команди, матчі, титули тощо.

    Проаналізуйте домен і напишіть SPARQL-запит для побудови бази даних.

2. Видобування фактів
    1. Напишіть програму, яка шукає статтю у Вікіпедії про сутність, що належить до вашого домена, та витягає текст цієї статті.

    2. Напишіть програму, яка опрацьовує текст статті (саме сирий текст, а не таблички, якщо такі є) та витягає з нього інформацію про ваш домен. Цю інформацію ви будете порівнювати зі сформованою базою даних.

3. Оцінювання результатів

    Розробіть метрику, яка покаже, наскільки інформація, яку ви дістали зі статті, збігається з інформацією в вашій базі даних. Скільки пропущеної інформації? Чи є часткові збіги? (Наприклад, ім'я СЕО збігається лише частково або ім'я СЕО збігається, а роки діяльності різні.)

Додайте ваші спостереження і висновки.

# Моя задача

- Обрав одного з моїх улюблених письменників-фантастів, Пола Андерсона, та його твори.

# Результати
## Перш за все, витягуємо твори Пола Андерсона із бази DBPedia

Запрос можна знайти у файлі [sparql.txt](sparql.txt)

```
PREFIX dbo: <http://dbpedia.org/ontology/>
PREFIX res:  <http://dbpedia.org/resource/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
SELECT DISTINCT ?writing ?collection
WHERE {
	?uri dbo:author res:Poul_Anderson .
        OPTIONAL {?uri dct:subject ?cat . 
                  ?cat rdfs:label ?collection } .
	?uri rdfs:label ?writing .
        FILTER (lang(?writing) = 'en')
}
```

Зберігаємо результати у [форматі tsv](sparql.tsv). Фрагмент:
```
"writing"	"collection"
"The Broken Sword"	"1950s fantasy novels"
"The Broken Sword"	"1954 American novels"
"Brain Wave"	"1954 American novels"
"Question and Answer (novel)"	"1954 American novels"
"Three Hearts and Three Lions"	"1961 American novels"
"Orbit Unlimited"	"1961 American novels"
"Fire Time"	"1974 American novels"
"A Midsummer Tempest"	"1974 American novels"
"Conan the Rebel"	"1980s fantasy novels"
"Orion Shall Rise"	"1983 American novels"
...
```

## Запуск poul_works_retriever.py 

Для того, щоб отримати місця в тексті [сторінки Вікіпедії 
про Пола Андерсона](https://en.wikipedia.org/wiki/Poul_Anderson), де згадано його 
роботи, маємо запустити скрипт *poul_works_retriever.py*:

```
python.exe D:/git-nlp/ss-prj-nlp-2019/students/SergeSotnyk/04-nlp-full-circle/FactChecking/poul_works_retriever.py
```

Після запуску, скрипт перевіряє, чи може вже є кєш цієї сторінки (файл 
"Poul Anderson.cache"). Якшо нема, то його буде закачано за допомогою пакету (ніколи не
здогадаєтеся, як він називаеться) wikipedia.

Далі перевіряється чи є файл "Poul Anderson.anno", в якому мануально анотовано всі 
входження творів Андерсона в тексті. Це зроблено за допомогою тегів "<*" та "*>". 
Цей файл нам потрібен тільки для того, щоб отримати показник якості розбору. Після 
перевірки, що обидва файла мають ідентичній контент (виключаючи теги), проводиться
основний етап пошуку творів. Якшо знайдено якісь нестиковки, програма покаже, що не
збігається (перший фрагмент, що відрізняється).

Алгоритм такий: 

- всі назви творів (перша колонка tsv-файлу), перетворюються на токени і далі на
леми та переводяться в нижній регистр (точніше, застосовується метод casefold(), щоб
правильно обробити різні кейси з юнікод-строками).
- перетворюємо всі токени тексту на леми в нижньому регістру, аналогично назвам.
- йдемо по реченням тексту, формуючи строки лем длиною від 1 до N (де N - найдовший 
ланцюг токенів в назвах). Якщо знайдемо таку саму послідовність токенів серед лем, то 
помічаємо оригінальну послідовність в тексті як знайдену назву твору.

Далі, перевіряемо, скільки творів було знайдено, як це число збігається із 
ground truth - анотованим файлом.

В оригінальній сторінці ми маємо 41 входження твору у тексті.
Алгоритм знайшов 15 місць, підозрілих на твори, з яких 2 виявилися хибними:

- В одному місці самоназва персонажу "un-man" збіглася із назвою твору.
- У другому місці, назва твору "The High Crusade" входить в більш довгу назву твору 
іншого автора про П. Андерсона: "Against Time's Arrow: The High Crusade of Poul 
Anderson." 

Інші типові показники якості:

* TP: 13
* FP: 2
* FN: 28
* Precision: 0.8666666666666667
* Recall: 0.3170731707317073
* F1: 0.4642857142857143

Лог запуску програми може бути знайдено в файлі ["log.txt"](log.txt).

Мене заінтригувало, чому ж так мало творів знайдено? Розгадка проста. Як виявилося,
база творів, що є в dbpedia - дуже неповна. І всі ті FN випадки, що я перевірив 
(десяток точно), просто відсутні в файлі [sparql.tsv](sparql.tsv). То ж треба
або поповнити tsv файл, або може в мене є якась помилка в запиті до бази.

## Baby, baby, one more time...

У зв'язку із зауваженнями від Мар'яни про те, що попередній варіант є чітерством і 
його треба переробити, для того, щоб знайти назви творів без бази, лише на якихось
правилах, було розроблено наступний алгоритм, який базується на тому, что в 
англійський вікі досить добре дотримуються правил капіталізації в назвах:

0. Рухаємося вздовж кожного із речень. Ланцюги токенів не перетинають межі речень.
0. Рухаємося по токенам spacy, зліва направо, з другого токену.
0. Начинаємо накопичувати токени в ланцюгу, якщо збігаються умови:
    - Токен починається з великої літери
    - Перед цим токеном є один із наступних токенів (лемма): {'novel', 'fiction', 
    'sequel', 'in'}
0. Продовжуємо ланцюг, поки в нас ідуть слова з великої літери, або з маленької іде 
стоп-слово (and, in, the, etc.) Як тільки ця умова не спрацьовує, передаємо накопичені
токени в аккумулятор творів і починаємо накопичувати токени з початку. Аналогично
зброс ланцюга в аккумулятор викликає ще закінчення речення, або пунктуаційні токени.
Токен, що спричинив сброс, в новий ланцюг не попадає.
0. Також, якщо в токені знайдено прізвище автора (у нашому випадку це "Anderson"), це
спричиняє сброс ланцюга без попадання в твори - навряд чи у автора буде твір, який 
називається його ж прізвищем. Скоріше це просто згадування автора, або твори інших
авторів та критиків про нього.

Цей алгоритм дав такі результати:

* Found entries number: 32
* tp: 16
* fp: 16
* fn: 25
* precision: 0.5
* recall: 0.3902439024390244
* f1: 0.4383561643835617

Можна ще поробити із правилами, але час вже спливає... А взагалі-то не так вже й 
погано вийшло. Якщо враховувати, що правила досить прості.

Новий лог можна знайти у [файлі log2.txt](log2.txt)
