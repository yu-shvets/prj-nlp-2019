{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\ssotn\\\\Anaconda3\\\\envs\\\\nlp\\\\python36.zip', 'C:\\\\Users\\\\ssotn\\\\Anaconda3\\\\envs\\\\nlp\\\\DLLs', 'C:\\\\Users\\\\ssotn\\\\Anaconda3\\\\envs\\\\nlp\\\\lib', 'C:\\\\Users\\\\ssotn\\\\Anaconda3\\\\envs\\\\nlp', '', 'C:\\\\Users\\\\ssotn\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\site-packages', 'C:\\\\Users\\\\ssotn\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages', 'C:\\\\Users\\\\ssotn\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\ssotn\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#!python -m spacy download en_core_web_lg\n",
    "#!python -m spacy download en_core_web_md\n",
    "\n",
    "nlp_en = spacy.load('en_core_web_md', disable=['ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Колокації\n",
    "\n",
    "```\n",
    "продовжте синонімний ряд дієслів: \"say\", \"tell\", \"speak\", \"claim\", \"communicate\"\n",
    "```\n",
    "\n",
    "Take the hi- and medium-orange synonims from https://www.thesaurus.com/browse/say:\n",
    "\n",
    "add, announce, answer, assert, claim, convey, declare, deliver, disclose, do, estimate, express, maintain, mention, read, repeat, reply, report, respond, reveal, speak, state, suggest, tell, voice, affirm, allege, communicate, conjecture, divulge, flap, gab, guess, imagine, imply, jaw, judge, lip, opine, orate, perform, pronounce, rap, recite, rehearse, relate, remark, render, rumor, spiel, utter, verbalize, yak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_words = [\"say\", \"add\", \"announce\", \"answer\", \"assert\", \"claim\", \"convey\", \"declare\", \"deliver\",\n",
    "        \"disclose\", \"do\", \"estimate\", \"express\", \"maintain\", \"mention\", \"read\", \"repeat\", \"reply\",\n",
    "        \"report\", \"respond\", \"reveal\", \"speak\", \"state\", \"suggest\", \"tell\", \"voice\", \"affirm\", \n",
    "        \"allege\", \"communicate\", \"conjecture\", \"divulge\", \"flap\", \"gab\", \"guess\", \"imagine\", \n",
    "        \"imply\", \"jaw\", \"judge\", \"lip\", \"opine\", \"orate\", \"perform\", \"pronounce\", \"rap\", \"recite\", \n",
    "        \"rehearse\", \"relate\", \"remark\", \"render\", \"rumor\", \"spiel\", \"utter\", \"verbalize\", \"yak\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "LyStatEntry = namedtuple('LyStatEntry', ['lemma', 'ly_adv'])\n",
    "    \n",
    "def make_ly_stats(text: str):\n",
    "    res = []\n",
    "    doc = nlp_en(text)\n",
    "    for t in doc:\n",
    "        if t.pos_!='ADV':\n",
    "            continue\n",
    "        if not str(t).lower().endswith('ly'):\n",
    "            continue\n",
    "        #print(t)\n",
    "        parent = None\n",
    "        head = t.head\n",
    "        if head==None or head==t:\n",
    "            continue\n",
    "        if t.dep_=='conj':\n",
    "            head = head.head\n",
    "        #print(head)\n",
    "        #print(f\"{head}:{head.dep_} -> {t}:{t.dep_}\")\n",
    "        if head.pos_=='VERB' and head.lemma_ in syn_words:\n",
    "            #print(\">>\"+head)\n",
    "            res.append(LyStatEntry(lemma = head.lemma_, ly_adv= str(t).lower()))\n",
    "        # elif head.\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[LyStatEntry(lemma='speak', ly_adv='dearly')]\n",
      "[]\n",
      "[LyStatEntry(lemma='claim', ly_adv='greatly')]\n",
      "[]\n",
      "[LyStatEntry(lemma='reply', ly_adv='sincerely'), LyStatEntry(lemma='reply', ly_adv='hopefully')]\n"
     ]
    }
   ],
   "source": [
    "print(make_ly_stats(\"\"\"-- Sheryl Crow at the Huffington Post9 ) \" I hear about Tony Snow and say to myself , well , stand up every day , lie to the American people at the behest of your dictator-esque boss and well , how could a cancer NOT grow in you .\"\"\"))\n",
    "print(make_ly_stats(\"\"\"Work for Fox News , spinning the truth in to a billion knots and how can your gut not rot ?\"\"\"))\n",
    "print(make_ly_stats(\"speak somebody dearly\"))\n",
    "print(make_ly_stats(\"honor somebody highly\")) \n",
    "print(make_ly_stats(\"claim somebody greatly\"))\n",
    "print(make_ly_stats(\"\"\"Speaking a week after Bhutto 's assassination in a shooting and suicide bombing , Musharraf denied there had been a security lapse and implied that Bhutto , who was greeting supporters through the sunroof of her armored vehicle at the time of the attack , was partly responsible .\"\"\"))\n",
    "print(make_ly_stats(\"Mariana replied me sincerely and hopefully.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def process_blog_texts():\n",
    "    with open('blog2008.txt', 'r', encoding=\"utf-8\") as inp:\n",
    "        total = 0\n",
    "        stat = defaultdict(lambda: defaultdict(int))\n",
    "        for head in tqdm(inp, total=303995):\n",
    "            # if total>5000:\n",
    "            #     break\n",
    "            head = head.strip()\n",
    "            stat_items = make_ly_stats(head)\n",
    "            total += 1\n",
    "            for item in stat_items:\n",
    "                stat[item.lemma][item.ly_adv] += 1\n",
    "        print(f\"Total lines: {total}, 'say'-verbs found: {len(stat)}\")\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6df4617c30481993579018226bdf8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=303995), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total lines: 303994, 'say'-verbs found: 45\n"
     ]
    }
   ],
   "source": [
    "# %load_ext line_profiler\n",
    "# %lprun -f make_ly_stats process_blog_texts()\n",
    "stat = process_blog_texts()\n",
    "# print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_statistics(stat):\n",
    "    with open('collocations.txt', 'w', encoding=\"utf-8\") as outp:\n",
    "        for k, v in stat.items():\n",
    "            s_values = sorted(v.items(), key=lambda x: x[1], reverse=True)\n",
    "            values_str = str(s_values[:10])[1:-1]\n",
    "            print(f\"{k}: {values_str}\", file=outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_statistics(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
