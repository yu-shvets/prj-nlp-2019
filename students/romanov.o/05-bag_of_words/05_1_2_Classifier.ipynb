{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Comment\n",
       "Rating         \n",
       "1           315\n",
       "2           210\n",
       "3           369\n",
       "4          1294\n",
       "5          3837"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('file:rozetka_mobile_reviews.json')\n",
    "df.groupby(['Rating']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розділимо усі рейтинги на два класи:\n",
    "- _позитивні_ - 5, 4\n",
    "- _негативні_ - 3, 2, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>5131</td>\n",
       "      <td>5131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Comment  Rating\n",
       "Sentiment                 \n",
       "Negative       894     894\n",
       "Positive      5131    5131"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'] = df['Rating'].apply(lambda x: 'Positive' if x > 3 else 'Negative')\n",
    "df.groupby(['Sentiment']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подвоїмо кількість негативних прикладів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df[df['Sentiment']=='Negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розділимо дані на два сети:\n",
    "- _тренувальний_ - 70%\n",
    "- _тестовий_  - 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.sample(frac=0.3)\n",
    "train_df = df.drop(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import pymorphy2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()  \n",
    "        return lambda doc: ([morph.parse(w)[0].normal_form for w in analyzer(doc)])\n",
    "    \n",
    "class BigramCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(BigramCountVectorizer, self).build_analyzer()\n",
    "        def bigram_analyzer(doc):\n",
    "            tokens = analyzer(doc)\n",
    "            return [' '.join(tokens[i:i+2]) for i in range(len(tokens)-1)]\n",
    "        return bigram_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(pipeline):\n",
    "    start = time.time()\n",
    "    \n",
    "    text_clf = Pipeline(pipeline)\n",
    "    text_clf = text_clf.fit(train_df.Comment, train_df.Sentiment)\n",
    "    test_df['Predicted'] = text_clf.predict(test_df.Comment)\n",
    "    \n",
    "    print(f'Execution time: {time.time()-start:.1f}s')\n",
    "    print(classification_report(test_df.Sentiment, test_df.Predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1. Naive Bayes без нормалізації словоформ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.3s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.81      0.42      0.55       556\n",
      "    Positive       0.82      0.96      0.89      1520\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2076\n",
      "   macro avg       0.81      0.69      0.72      2076\n",
      "weighted avg       0.82      0.82      0.80      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model([('vect', CountVectorizer()),\n",
    "                ('clf', MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2. Naive Bayes + нормалізація словоформ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 23.8s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.52      0.62       556\n",
      "    Positive       0.84      0.94      0.89      1520\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      2076\n",
      "   macro avg       0.80      0.73      0.75      2076\n",
      "weighted avg       0.82      0.83      0.82      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model([('vect', StemmedCountVectorizer()),\n",
    "                ('clf', MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3. Naive Bayes + біграми:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.7s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.35      0.47       556\n",
      "    Positive       0.80      0.95      0.87      1520\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2076\n",
      "   macro avg       0.77      0.65      0.67      2076\n",
      "weighted avg       0.78      0.79      0.76      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model([('vect', BigramCountVectorizer()),\n",
    "                ('clf', MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1. SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.3s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.47      0.58       556\n",
      "    Positive       0.83      0.94      0.88      1520\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2076\n",
      "   macro avg       0.79      0.71      0.73      2076\n",
      "weighted avg       0.81      0.82      0.80      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model([('vect', CountVectorizer()),\n",
    "                ('clf-svm', SGDClassifier(max_iter=5, tol=1e-3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. SVM + нормалізація словоформ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 24.0s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.50      0.60       556\n",
      "    Positive       0.84      0.94      0.89      1520\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2076\n",
      "   macro avg       0.80      0.72      0.74      2076\n",
      "weighted avg       0.82      0.82      0.81      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model([('vect', StemmedCountVectorizer()),\n",
    "                ('clf-svm', SGDClassifier(max_iter=5, tol=1e-5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.3s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.37      0.51       556\n",
      "    Positive       0.81      0.97      0.88      1520\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2076\n",
      "   macro avg       0.82      0.67      0.70      2076\n",
      "weighted avg       0.82      0.81      0.78      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model([('vect', CountVectorizer()),\n",
    "                ('clf-lr', LogisticRegression(solver='liblinear'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.3s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.45      0.56       556\n",
      "    Positive       0.82      0.94      0.88      1520\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2076\n",
      "   macro avg       0.78      0.70      0.72      2076\n",
      "weighted avg       0.80      0.81      0.79      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model([('vect', CountVectorizer()),\n",
    "                ('clf-lr', Perceptron(max_iter=5, tol=1e-5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Спостереження\n",
    "1. Усі лінійні класифікатори мають схожі результати\n",
    "2. Нормалізація слів трішки покращує результати\n",
    "3. Застосування tf-idf погіршує якість класифікації цього датасету\n",
    "4. Модель Bag-of-words є занадто простою для гарної класифікаці негативних відгуків.\n",
    "Наприклад: _\"гарно працює\"_, _\"не працює\"_, _\"не ламається\"_ неможливо розрізнити лише за наявністю певних слів у тексті."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "1. [Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK.](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
