Для аналізу даних було обрано категорію "Побутова техніка", з якої вдалося видобути 7192 коментарі (українською, з оцінкою та текстом).
Ці дані було проаналізовано за допомогою MultinomialNB та SGDClassifier класифікаторів. Також була спроба використати словник тональності, але це призвело до зниження точності

| Класифікатор                                             | Результат |
|----------------------------------------------------------|-----------|
| 1. MultinomialNB (з використанням словника тональностей) | 0.493     |
| 2. SGDClassifier (з використанням словника тональностей) | 0.468     |
| 3. MultinomialNB                                         | 0.641     |
| 4. SGDClassifier                                         | 0.667     |
| 5. SGDClassifier (4 + переваги та недоліки)              | 0.696     |
| 6. SGDClassifier (5 + оцінка корисності коментаря)       | 0.691     |
| 7. SGDClassifier (4 + чи купував коментатор товар)       | 0.693     |

Оновлення:
Також було проаналізовано категорію комп'ютери та ноутбуки (https://rozetka.com.ua/computers-notebooks/c80253/) - 7784 коментарі українсьуою з оцінкою.
Для цієї категорії оцінки настуцпні:

| Класифікатор                                             | Результат |
|----------------------------------------------------------|-----------|
| 1. MultinomialNB (з використанням словника тональностей) | 0.653     |
| 2. SGDClassifier (з використанням словника тональностей) | 0.634     |
| 3. MultinomialNB                                         | 0.716     |
| 4. SGDClassifier                                         | 0.733     |
| 5. SGDClassifier (4 + переваги та недоліки)              | 0.741     |
| 6. SGDClassifier (5 + оцінка корисності коментаря)       | 0.747     |
| 7. SGDClassifier (4 + чи купував коментатор товар)       | 0.743     |

### Дані по зведеному датасету (14949 коментарів українською з оцінками):

| Класифікатор                                             | Результат |
|----------------------------------------------------------|-----------|
| 1. MultinomialNB (з використанням словника тональностей) | 0.622     |
| 2. SGDClassifier (з використанням словника тональностей) | 0.596     |
| 3. MultinomialNB                                         | 0.683     |
| 4. SGDClassifier                                         | 0.707     |
| 5. SGDClassifier (4 + переваги та недоліки)              | 0.725     |
| 6. SGDClassifier (5 + оцінка корисності коментаря)       | 0.726     |
| 7. SGDClassifier (4 + чи купував коментатор товар)       | 0.726     |

Як ми можемо бачити, найточнішим був SGDClassifier, але на різних датасетах найкращі результати давали комбінації різних фіч (переваги та недоліки, оцінка корисності коментаря, чи купував коментатор товар)

### Точність для кожного класу:
|                    Класифікатор                    |   1   |   2   |   3   |   4   |   5   |
|:--------------------------------------------------:|:-----:|:-----:|:-----:|:-----:|:-----:|
|              Зі словником тональностей             |       |       |       |       |       |
|                  1. MultinomialNB                  | 0.122 | 0.021 | 0.046 | 0.092 | 0.956 |
|                  2. SGDClassifier                  | 0.388 | 0.108 | 0.078 | 0.244 | 0.817 |
|     3. SGDClassifier (2 + переваги та недоліки)    | 0.422 | **0.130** | **0.109** | **0.252** | 0.844 |
| 4. SGDClassifier (3 + оцінка корисності коментаря) | 0.433 | **0.130** | **0.109** | 0.224 | 0.862 |
| 5. SGDClassifier (3 + чи купував коментатор товар) | 0.411 | **0.130** | **0.109** | 0.228 | 0.851 |
|              Без словника тональностей             |       |       |       |       |       |
|                  1. MultinomialNB                  | 0.125 |   0   | 0.017 |  0.13 | **0.976** |
|                  2. SGDClassifier                  | 0.379 | 0.047 | 0.047 | 0.125 | 0.968 |
|     3. SGDClassifier (2 + переваги та недоліки)    | **0.472** |  0.11 | 0.055 | 0.175 | 0.971 |
| 4. SGDClassifier (3 + оцінка корисності коментаря) | **0.472** | 0.094 |  0.06 | 0.172 | 0.973 |
| 5. SGDClassifier (3 + чи купував коментатор товар) | **0.472** | 0.102 |  0.06 | 0.175 | 0.972 |

### Точність для кожного класу для збалансованого корпусу (по 475 коментарів кожного класу):

|                    Класифікатор                    |   1   |   2   |   3   |   4   |   5   |  Mean |
|:--------------------------------------------------:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|
|              Зі словником тональностей             |       |       |       |       |       |       |
|                  1. MultinomialNB                  | **0.563** | **0.487** | 0.260 | 0.181 | 0.105 | 0.319 |
|                  2. SGDClassifier                  | 0.490 | 0.307 | 0.282 | 0.204 | 0.210 | 0.298 |
|     3. SGDClassifier (2 + переваги та недоліки)    | **0.563** | 0.256 | 0.260 | 0.204 | 0.289 | 0.314 |
| 4. SGDClassifier (3 + оцінка корисності коментаря) | **0.563** | 0.307 | 0.239 | 0.159 | 0.263 | 0.306 |
| 5. SGDClassifier (3 + чи купував коментатор товар) | 0.527 | 0.256 | **0.304** | 0.204 | 0.368 | 0.331 |
|              Без словника тональностей             |       |       |       |       |       |       |
|                  1. MultinomialNB                  | 0.553 | 0.378 | 0.214 | 0.226 | 0.406 | 0.355 |
|                  2. SGDClassifier                  | 0.462 | 0.290 | 0.245 | 0.321 | 0.436 | 0.350 |
|     3. SGDClassifier (2 + переваги та недоліки)    | 0.462 | 0.364 | 0.300 | 0.357 | 0.624 | 0.421 |
| 4. SGDClassifier (3 + оцінка корисності коментаря) |  0.5  | 0.358 | 0.300 | 0.379 | 0.616 | **0.430** |
| 5. SGDClassifier (3 + чи купував коментатор товар) | 0.484 | 0.337 | 0.276 | **0.386** | **0.639** | 0.424 |


Як ми можемо бачити, на сбалансованому датасеті найвища середня точність вийшла для SVM з урахуванням переваг/недоліків та оцінки корисності коментаря, але без використання тонального словника.

FScore для `4. SGDClassifier (3 + оцінка корисності коментаря)`

              precision    recall  f1-score   support

           1       0.41      0.50      0.45       132
           2       0.44      0.36      0.39       148
           3       0.42      0.30      0.35       163
           4       0.34      0.38      0.36       137
           5       0.50      0.62      0.55       133

    micro avg      0.42      0.42      0.42       713
    macro avg      0.42      0.43      0.42       713
    weighted avg   0.42      0.42      0.42       713