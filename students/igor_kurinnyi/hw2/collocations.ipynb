{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = [\n",
    "    'say', 'tell', 'speak', 'claim', \n",
    "    'communicate', 'convey', 'inform', \n",
    "    'declare', 'explain', 'announce', \n",
    "    'instruct', 'mention', 'broadcast', 'disclose'\n",
    "]\n",
    "\n",
    "verb_adv_stats = dict((v, defaultdict(int)) for v in verbs)\n",
    "\n",
    "verb_pattern = lambda verb: [{'LEMMA': verb, 'POS': 'VERB'}]\n",
    "is_ly_adv = lambda t: (t.pos_ == 'ADV') and (t.lower_[-2:] == 'ly')\n",
    "\n",
    "\n",
    "def process_match(matcher, doc, i, matches):\n",
    "    verb = doc[matches[i][1]]\n",
    "    advs = find_advs(verb)\n",
    "    count_verb_adv_pairs(verb, advs)\n",
    "    \n",
    "def find_advs(verb):\n",
    "    advs = list(filter(is_ly_adv, verb.rights))\n",
    "    for adv in advs:\n",
    "        advs.extend(filter(is_ly_adv, adv.conjuncts))\n",
    "    return advs\n",
    "\n",
    "def count_verb_adv_pairs(verb, advs):\n",
    "    for adv in advs:\n",
    "        verb_adv_stats[verb.lemma_][adv.lower_] += 1\n",
    "        \n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "for verb in verbs:\n",
    "    matcher.add(verb.upper(), process_match, verb_pattern(verb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for faster processing\n",
    "verb_pattern = '''(\n",
    "      say|said|\n",
    "      tell|told|\n",
    "      speak|spoke|\n",
    "      claim|communicate|convey|\n",
    "      inform|declare|explain|\n",
    "      announce|instruct|mention|\n",
    "      broadcast|disclose'\n",
    ")'''\n",
    "\n",
    "def line_reader(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            if re.search(verb_pattern, line, re.VERBOSE):\n",
    "                yield line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOG_FILE = '../../../tasks/02-structural-linguistics/blog2008.txt'\n",
    "n_lines = sum(1 for _ in line_reader(BLOG_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44630/44630 [04:31<00:00, 164.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(nlp.pipe(line_reader(BLOG_FILE), disable=['ner']), total=n_lines):\n",
    "    matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-== SAY ==-\n",
      "       recently: 35 \n",
      "     repeatedly: 28 \n",
      "       publicly: 26 \n",
      "     explicitly: 12 \n",
      "      privately: 10 \n",
      "        clearly: 9  \n",
      "         simply: 8  \n",
      "        bluntly: 8  \n",
      "         flatly: 7  \n",
      "   definitively: 6  \n",
      "\n",
      "\n",
      "\n",
      "-== TELL ==-\n",
      "       recently: 10 \n",
      "     personally: 4  \n",
      "        exactly: 3  \n",
      "       reliably: 3  \n",
      "        frankly: 2  \n",
      "     repeatedly: 2  \n",
      "         slowly: 2  \n",
      "   specifically: 2  \n",
      "      privately: 2  \n",
      "   definitively: 2  \n",
      "\n",
      "\n",
      "\n",
      "-== SPEAK ==-\n",
      "       directly: 31 \n",
      "       publicly: 12 \n",
      "       fiercely: 12 \n",
      "        briefly: 8  \n",
      "     forcefully: 8  \n",
      "         loudly: 7  \n",
      "        clearly: 7  \n",
      "         openly: 7  \n",
      "     eloquently: 6  \n",
      "    anonymously: 5  \n",
      "\n",
      "\n",
      "\n",
      "-== CLAIM ==-\n",
      "       publicly: 2  \n",
      "     previously: 1  \n",
      "        falsely: 1  \n",
      "         loudly: 1  \n",
      "    indignantly: 1  \n",
      "         really: 1  \n",
      "    erroneously: 1  \n",
      "    idiotically: 1  \n",
      "    incorrectly: 1  \n",
      "       recently: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== COMMUNICATE ==-\n",
      "       directly: 3  \n",
      "    effectively: 2  \n",
      "         freely: 1  \n",
      "     indirectly: 1  \n",
      "         loudly: 1  \n",
      "          daily: 1  \n",
      "      regularly: 1  \n",
      "        quickly: 1  \n",
      "        broadly: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== CONVEY ==-\n",
      "     accurately: 2  \n",
      "        sharply: 1  \n",
      "      privately: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== INFORM ==-\n",
      "     personally: 2  \n",
      " simultaneously: 1  \n",
      "      literally: 1  \n",
      "  unequivocally: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== DECLARE ==-\n",
      "  unequivocally: 3  \n",
      "      ominously: 2  \n",
      "         openly: 2  \n",
      "         surely: 1  \n",
      "       publicly: 1  \n",
      "        clearly: 1  \n",
      "    immediately: 1  \n",
      "          early: 1  \n",
      "        stiffly: 1  \n",
      "       suddenly: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== EXPLAIN ==-\n",
      "        clearly: 8  \n",
      "          fully: 3  \n",
      "      patiently: 1  \n",
      "      elegantly: 1  \n",
      "        quickly: 1  \n",
      "   successfully: 1  \n",
      "         nicely: 1  \n",
      "         thusly: 1  \n",
      "         neatly: 1  \n",
      "       directly: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== ANNOUNCE ==-\n",
      "          early: 4  \n",
      "        shortly: 3  \n",
      "       publicly: 1  \n",
      "    essentially: 1  \n",
      "         openly: 1  \n",
      "   unexpectedly: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== INSTRUCT ==-\n",
      "    erroneously: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== MENTION ==-\n",
      "    prominently: 2  \n",
      "     repeatedly: 1  \n",
      "   respectively: 1  \n",
      "   continuously: 1  \n",
      "      favorably: 1  \n",
      "      peaceably: 1  \n",
      "     indirectly: 1  \n",
      "parenthetically: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== BROADCAST ==-\n",
      "         widely: 3  \n",
      "     nationally: 1  \n",
      "\n",
      "\n",
      "\n",
      "-== DISCLOSE ==-\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for verb, adv_counts in verb_adv_stats.items():\n",
    "    top_adv = sorted(adv_counts.items(), key=lambda x: -x[1])[:10]\n",
    "    top_adv_str = ''.join(['{:>15}: {:<3}\\n'.format(w, c) for w, c in top_adv])\n",
    "    print('-== {} ==-'.format(verb.upper()))\n",
    "    print(top_adv_str)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prj-nlp-2019",
   "language": "python",
   "name": "prj-nlp-2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
