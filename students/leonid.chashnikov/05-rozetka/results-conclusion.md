Пробував два варіанти розподілу коментарів:
  - на три категорії - негативна (1-2), посередня (3), позитивна (4-5)
  - на дві категорії - негативна (1-2), позитивна (4-5)
 
З моделей пробував Naive Bayes, Perceptron і Logistic Regression.
Перцептрон стабільно показує кращий результат,
байєс і логістична регресія - трохи "хаотично" розділяють друге-третє місце.

Додавання тону трохи покращує score, але, чомусь, дуже мало.
Можливо, варто спробувати рахувати його по-іншому,
або не для речення в цілому, а для кожного слова.
(Хоча коли вручну перевіряв оцінки речень, сентимент речення досить непогано співпадав з позитивним-негативним класом).

Для створення BoW використовував CountVectorizer і TfidfVectorizer, 
великої різниці не помітив, CountVectorizer навіть був трохи краще, чому я здивований. 

Перехід від трьох категорій до двох, звісно, значно покращує f1 score,
плюс сам датасет вийшов дуже перекошений (позитивних 2321, негативних 222, нейтральних 149).

Щоб трохи збалансувати його, пробував змінити категоризацію на "негативні 1-3" і "позитивні 4-5",
це ще трохи покращило якість, плюс, неочікувано, вперед по f1-score вирвалась логістична регресія.
Потрібно буде додатково спробувати збалансувати класи ще більше, можливо, викинувши більше половини позитивних коментарів.

Лемматизація тексту трохи покращила результати, але, нажаль, не настільки сильно, як я очікував.
Але, здається, сильно пришвидшила тренування моделей.