{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs of a wonderful website of Ukrainian poetry\n",
    "url_base = \"https://onlyart.org.ua\"\n",
    "\n",
    "# We intend to scrape three main categories:\n",
    "url_classics = \"/ukrainian-poets/\"\n",
    "url_modern = \"/modern-ukrainian-poets/\"\n",
    "url_live = \"/live/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: The scraper is by no means complete due to peculiar behavior of BeautifulSoup\n",
    "that makes it problematic to search for divs with a specific class. \n",
    "\n",
    "The general strategy, however, is to scrape all three sections (the 'classics' and \n",
    "'modern' sections look nearly identical, the 'live' section will require a slightly\n",
    "different approcah with pagination support, different author parsing, etc.)\n",
    "\n",
    "Since I'm not sure about the best way to store the scraped data, we will tentaitvely\n",
    "store it in JSON or pickled dicts like so:\n",
    "\n",
    "{\n",
    "    poet_id: {\n",
    "        poem_id: int,\n",
    "        poem_title: str,\n",
    "        poem_text: str\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import json\n",
    "\n",
    "def scrape_main(url):\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.text, 'html.parser')\n",
    "    \n",
    "    divs = soup.find_all(\"div\")\n",
    "    \n",
    "    for div in divs:\n",
    "        print(div)\n",
    "        try:\n",
    "            print(div['id'])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # poet_portraits = [div for div in divs if div.attrs['class'] == 'teaser']\n",
    "        \n",
    "    # for poet in poet_portraits:\n",
    "    #     print(poet)\n",
    "    \n",
    "    # Get poets' index pages from main page\n",
    "\n",
    "scrape_main(url_base + url_classics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
