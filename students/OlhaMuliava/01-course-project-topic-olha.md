## Абстрактне узагальнення тексту новин

Знайти ключові слова, часті словосполучення, іменовані сутності і скласти з них речення.
Як один із можливих кроків задача Entity linking, як саме іменовані сутності пов'язані.

Named Entities буду знаходити StanfordNERTagger. Я отримую певні дані - Person, Org, Location, other. Додатково перевіряти можна через Wiki API, можна знайти датасети локацій (країн, міст). Наступний аналіз, подивитись, які іменовані сутності вживаються разом у реченнях. Побудувати залежності (Spacy parser, Stanford parser, Language modeling (predict next word), entity linking).

Треба ще звернути увагу, що у перших реченнях новини чамто вже є узагальнення. Можна це використати як надати вагу сутностям, ключовим словам більшу, які вище знаходяться.

Ще вивчу підіхд нейронних мереж для цієї задачі - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.823.8025&rep=rep1&type=pdf

Дані (буду працювати тільки з англійською мовою):
1. CNN Daily Email - датасет має статті новин з саммеру (вже завантажила)
Два наступних потенційно гарні (щоб їх отримати треба писати запити).
2. DUC (Document Understanding Conferences - Past Data)
3. TAC (Text Analysis Conference (TAC) Data
4. Датасет відгуків на амазоні конкретних товарів з саммері (можливо використаю).

Для оцінки:
Ці метрики застосовуються для проанотованрих текстів (як пункт 1 в Даних).
ROUGE (recall-oriented measure), показник відношення кількості вгаданих н-грам до загальної кількості в узагальненні.
Meteor metric враховує повне співпадіння слів, стеми, синоніми (за WordNet, ConceptNet наприклад).
